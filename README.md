# üéØ An√°lisis BERTopic para Discursos Pol√≠ticos

Script automatizado para an√°lisis de t√≥picos en discursos parlamentarios usando BERTopic.

## üìã Requisitos

- Python 3.8 o superior
- Archivos `.txt` con discursos en espa√±ol
- ~100 documentos (optimizado para corpus peque√±o)

## üöÄ Instalaci√≥n

### 1. Clonar/descargar el proyecto

```bash
git clone https://github.com/FerCipriani/Proyecto-IVE.git
cd Proyecto-IVE
```

### 2. Crear entorno virtual

```bash
python -m venv venv
```

### 3. Activar entorno virtual

**Windows (PowerShell):**
```bash
venv\Scripts\Activate.ps1
```

**Windows (CMD):**
```bash
venv\Scripts\activate.bat
```

**Linux/Mac:**
```bash
source venv/bin/activate
```

### 4. Instalar dependencias

```bash
pip install -r requirements.txt
```

Si fallas por timeout, usa:
```bash
pip install --timeout=300 -r requirements.txt
```

## üìÇ Estructura de Archivos

```
Proyecto-IVE/
‚îÇ
‚îú‚îÄ‚îÄ IVEDip/                          # Directorio con archivos .txt
‚îÇ   ‚îú‚îÄ‚îÄ AFIRMATIVO_discurso1.txt
‚îÇ   ‚îú‚îÄ‚îÄ NEGATIVO_discurso2.txt
‚îÇ   ‚îú‚îÄ‚îÄ ABSTENCION_discurso3.txt
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ analisis_bertopic_discursos.py  # Script principal
‚îú‚îÄ‚îÄ requirements.txt                # Dependencias
‚îî‚îÄ‚îÄ README.md                       # Este archivo
```

## ‚ñ∂Ô∏è Uso

### Ejecuci√≥n b√°sica

```bash
python analisis_bertopic_discursos.py
```

### Salida

El script genera un archivo Excel con timestamp:
```
bertopic_resultados_YYYYMMDD_HHMMSS.xlsx
```

### Hojas del Excel

1. **Resultados**: Cada documento con su t√≥pico asignado y probabilidad
2. **Resumen_Topicos**: Estad√≠sticas por t√≥pico
3. **Votos_x_Topico**: Distribuci√≥n de votos por t√≥pico
4. **Info_Topicos_Detallada**: Informaci√≥n completa de cada t√≥pico

## üîß Ajuste de Par√°metros

### Cambiar directorio de entrada

En `analisis_bertopic_discursos.py`, l√≠nea 20:

```python
TXT_DIR = "IVEDip"  # Cambiar por tu directorio
```

### Ajustar clustering (si hay problemas)

En la funci√≥n `create_bertopic_model()`:

#### üîπ **Problema: Demasiados t√≥picos peque√±os**

```python
hdbscan_model = hdbscan.HDBSCAN(
    min_cluster_size=10,     # ‚¨ÜÔ∏è Aumentar (default: 6)
    min_samples=5,           # ‚¨ÜÔ∏è Aumentar (default: 3)
    ...
)

umap_model = UMAP(
    n_neighbors=15,          # ‚¨ÜÔ∏è Aumentar (default: 12)
    ...
)
```

#### üîπ **Problema: Muchos documentos sin t√≥pico (-1)**

```python
hdbscan_model = hdbscan.HDBSCAN(
    min_cluster_size=4,      # ‚¨áÔ∏è Reducir (default: 6)
    min_samples=2,           # ‚¨áÔ∏è Reducir (default: 3)
    ...
)
```

#### üîπ **Ajustar n√∫mero de t√≥picos finales**

En la funci√≥n `analizar_documentos()`, l√≠nea ~150:

```python
topic_model_reduced = topic_model.reduce_topics(
    docs_clean,
    nr_topics=10  # Cambiar seg√∫n necesidad (5-15)
)
```

### Ajustar stopwords

En `create_bertopic_model()`, agregar palabras espec√≠ficas del dominio:

```python
spanish_stopwords = [
    # ... stopwords existentes ...
    # Agregar palabras propias del contexto:
    "se√±or", "se√±ora", "diputado", "diputada", "honorable",
]
```

## üìä Interpretaci√≥n de Resultados

### Columnas principales del Excel

| Columna | Descripci√≥n |
|---------|-------------|
| `Archivo` | Nombre del archivo .txt |
| `Tipo_Voto` | AFIRMATIVO / NEGATIVO / ABSTENCION |
| `Topico` | N√∫mero del t√≥pico asignado (-1 = sin t√≥pico) |
| `Probabilidad_Topico` | Confianza de la asignaci√≥n (0-1) |
| `Palabras_Clave_Topico` | Top 10 palabras del t√≥pico |
| `Resumen_Texto` | Primeros 200 caracteres |
| `Texto_Completo` | Texto completo del documento |

### Entendiendo los t√≥picos

- **T√≥pico -1**: Documentos "outliers" (no asignados)
- **Probabilidad alta** (>0.7): Asignaci√≥n confiable
- **Probabilidad baja** (<0.3): Revisar manualmente

## üé® Visualizaciones (Opcional)

Descomentar al final de `analizar_documentos()`:

```python
# Generar visualizaciones HTML
fig = topic_model_reduced.visualize_topics()
fig.write_html("topics_map.html")

fig2 = topic_model_reduced.visualize_barchart(top_n_topics=10)
fig2.write_html("topics_barchart.html")
```

## ‚ö†Ô∏è Soluci√≥n de Problemas

### Error: "No se encontraron documentos"

- Verificar que `TXT_DIR` apunte al directorio correcto
- Verificar que los archivos tengan extensi√≥n `.txt`

### Error: Timeout al instalar paquetes

```bash
pip install --timeout=300 -r requirements.txt
```

### Error: Memoria insuficiente

Reducir el tama√±o del modelo de embeddings:

```python
embedding_model = SentenceTransformer(
    "paraphrase-multilingual-mpnet-base-v2"  # Modelo m√°s ligero
)
```

### Resultados poco interpretables

1. **Revisar stopwords**: Agregar palabras frecuentes del dominio
2. **Aumentar min_df**: Filtrar palabras raras
3. **Reducir t√≥picos**: Usar `nr_topics` m√°s bajo (6-8)

## üìù Notas

- **Corpus peque√±o** (~100 docs): Es normal tener algunos outliers (-1)
- **Primera ejecuci√≥n**: Puede tardar 5-10 minutos descargando modelos
- **Ejecuciones posteriores**: M√°s r√°pidas (modelos en cach√©)

## ü§ù Contacto

Para dudas o mejoras:
- Abrir un issue en GitHub
- Contactar a [tu email]

---

**Versi√≥n**: 1.0  
**√öltima actualizaci√≥n**: Enero 2026
